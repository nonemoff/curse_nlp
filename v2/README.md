# NLP Курсовая работа v2

## Описание

Автоматизированная система анализа текста информационного ресурса по предметной области "Алгоритмы консенсуса в распределённых системах".

## Возможности

- ✅ Извлечение текста из PDF файлов
- ✅ Частотный анализ (закон Ципфа, характеристики M, N, K_R, K_I)
- ✅ Терминологический указатель (TF-IDF, N-граммы, аббревиатуры)
- ✅ Именной указатель (NER для русского и английского)
- ✅ Кеширование промежуточных результатов
- ✅ Визуализация (графики Ципфа и накопления)

## Установка

```bash
cd v2

# Создать виртуальное окружение
python -m venv venv
source venv/bin/activate  # Linux/Mac
# или venv\Scripts\activate  # Windows

# Установить зависимости
pip install -r requirements.txt

# Скачать модели
python -m spacy download en_core_web_sm
python -c "import nltk; nltk.download('stopwords'); nltk.download('wordnet'); nltk.download('omw-1.4')"
```

## Использование

```bash
# Полный пайплайн
python main.py all

# Отдельные этапы
python main.py extract    # Извлечение из PDF
python main.py analyze    # Частотный анализ
python main.py terms      # Терминологический указатель
python main.py names      # Именной указатель

# Утилиты
python main.py status     # Статус кеша
python main.py clear      # Очистить кеш
```

## Структура проекта

```
v2/
├── main.py                  # CLI точка входа
├── config.py                # Конфигурация
├── requirements.txt         # Зависимости
├── core/                    # Модули обработки
│   ├── cache.py             # Кеширование
│   ├── pdf_parser.py        # Извлечение из PDF
│   ├── preprocessor.py      # Токенизация и лемматизация
│   ├── frequency.py         # Частотный анализ
│   ├── term_index.py        # Терминологический указатель
│   └── ner.py               # Именной указатель (NER)
├── data/                    # Словари и конфигурация
│   ├── domain_terms.txt     # Словарь предметной области (319)
│   ├── products.txt         # Программные продукты
│   ├── abbr_stopwords.txt   # Стоп-слова аббревиатур
│   ├── location_abbr.txt    # Сокращения топонимов
│   ├── journal_markers.txt  # Маркеры журналов
│   └── address_markers.txt  # Маркеры адресов
├── cache/                   # Кеш результатов (.pkl)
└── output/                  # Результаты анализа
    ├── extracted/           # Извлечённые тексты (.txt)
    ├── frequency_dict.csv   # Частотный словник
    ├── statistics.txt       # Статистика M, N, K_R, K_I
    ├── term_index.csv       # Терминологический указатель
    ├── abbreviations.csv    # Аббревиатуры
    ├── name_index.csv       # Именной указатель
    └── graphs/              # Графики
        ├── zipf.png         # Закон Ципфа
        └── cumulative.png   # Накопление лексики
```

## Конфигурация

Все настройки находятся в `config.py`:

```python
# Частотный анализ
MIN_WORD_LENGTH = 3                # Минимальная длина слова
TOP_WORDS_LIMIT = 1000             # Топ слов для анализа
CORE_LEXICON_THRESHOLD = 0.5       # Порог ядра лексики (50%)

# Терминологический указатель
MIN_TERM_FREQUENCY = 3             # Минимальная частота термина
MAX_NGRAM_LENGTH = 3               # Максимальная длина N-грамм
DOMAIN_BOOST = 2.0                 # Усиление для терминов из словаря

# Именной указатель
MIN_ENTITY_FREQUENCY = 2           # Минимальная частота сущности
MIN_PERSON_FREQUENCY = 1           # Минимальная частота персоналий
```

## Словари данных

Все словари редактируются в `data/*.txt`:

- **domain_terms.txt** — термины предметной области (319 терминов)
- **products.txt** — программные продукты
- **abbr_stopwords.txt** — исключения для аббревиатур

После изменения словарей:
```bash
python main.py clear  # Очистить кеш
python main.py all    # Пересчитать
```

## Результаты

### Задание 1: Информационный ресурс
- 15 PDF файлов
- 334,475 знаков (8.36 а.л.)
- 46.8% на английском языке

### Задание 2: Частотный анализ
- M = 26,665 токенов
- N = 6,084 леммы
- K_R = 26.35 (разнообразие)
- K_I = 4.38 (информативность)
- Ядро лексики = 417 слов

### Задание 3: Терминологический указатель
- 3,170 терминов
  - 1,724 однословных
  - 1,034 двухсловных
  - 388 трёхсловных
  - 24 аббревиатуры
- 176 терминов из словаря ПО (5.6%)

### Задание 4: Именной указатель
- 36 именованных сущностей
  - 10 персоналий
  - 3 организации
  - 8 топонимов
  - 15 программных продуктов

## Технологии

- **Python 3.13**
- **PyMuPDF** — извлечение из PDF
- **pymorphy3** — морфология русского
- **natasha** — NER для русского
- **spacy** — NER для английского
- **nltk** — NLP инструменты
- **pandas** — обработка данных
- **matplotlib** — визуализация
- **rich** — красивый вывод в терминале

## Производительность

На Apple M1:
- С кешем: **0.5 секунды**
- Без кеша: **18 секунд**

## Авторы

- **Студент:** Мвушаков В., группа 221-329
- **Преподаватели:**
  - к.т.н., профессор Ю.Н. Филиппович
  - ассистент В.А. Филиппович

## Лицензия

Курсовой проект, 2026
